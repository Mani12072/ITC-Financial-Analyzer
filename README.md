# ğŸ“Š ITC Financial Analyzer APP â€“ AI-Powered Financial Q&A

An interactive AI tool designed to explore **ITC Ltdâ€™s financial journey** â€” revenues, profitability, and performance â€” via a **chat-based interface** powered by **web scraping**, **vector embeddings**, and **LLMs**.

---

## ğŸŒŸ Key Capabilities

- ğŸ¤– **Smart Data Scraper**: Real-time financial disclosures from ITCâ€™s website using *Firecrawl*, *Crew AI*, or *Tavily*.
- ğŸ§¬ **Embedding Engine**: Transforms financial text into vector embeddings for intelligent retrieval.
- ğŸ§  **Conversational AI**: Chat with a financial assistant that pulls insights directly from ITCâ€™s disclosures.
- ğŸ–¥ï¸ **Streamlit Interface**: Clean, interactive dashboard to ask financial queries and receive grounded answers.

---

## ğŸ”§ Project Modules and Pipeline

### ğŸ“ 1. Data Scraping (`/scraper`)
**Goal**: Extract ITCâ€™s 2023 & 2024 quarterly reports and consolidated financial presentations.

**Tools Used**:  
- ğŸ”¥ Firecrawl or ğŸ¤– Tavily API  
- ğŸ“„ Scraped PDF content from:
  - Annual Reports (2023, 2024)
  - Quarterly Reports (Q1â€“Q4)
  - Consolidated & Standalone Statements

### ğŸ§‘â€ğŸ’» Example: Using **Tavily API** for Scraping

Tavily API helps scrape and extract content from PDFs, including detailed metadata. Below is an example of how to use the **Tavily API** to scrape financial reports:

#### Step 1: Install Tavily

```bash
from tavily import Tavily

# Initialize the Tavily client with your API key
api_key = "your_tavily_api_key"
client = Tavily(api_key)

# Define the URL of the financial report you want to scrape
url = "https://www.itcportal.com/investor-relations/financial-reports/"

# Scrape the PDF data (ensure you have the correct URL for the document)
response = client.scrape_pdf(url)

# Extract text and metadata
extracted_text = response['text']  # Raw financial data text
metadata = response['metadata']   # Metadata like document type, date, etc.

# Print the extracted data
print(f"Extracted Text: {extracted_text[:500]}...")  # First 500 characters of the report
print(f"Metadata: {metadata}")

```
**Output**: Extracted raw text + metadata


### ğŸ“ 2. Data Storage in SQLite (`/database`)
**Goal**: Store the scraped financial data in a structured SQLite database for easy querying and analysis.

**Steps**:
- **Create a SQLite database** to store scraped financial documents.
- Store relevant metadata, such as document type, date, and page number, along with the extracted text.
- Store the extracted **raw financial data** for further processing.

**SQLite Schema Example**:
```sql
CREATE TABLE financial_reports (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    document_type TEXT,
    year INTEGER,
    quarter INTEGER,
    report_text TEXT,
    metadata JSON
);
```
### ğŸ§  3. Embedding Layer (`/embeddings`)
**Goal**: Convert scraped data into searchable vector format

**Steps**:
- ğŸ”„ Clean & chunk text using `RecursiveCharacterTextSplitter`
- âš™ï¸ Generate embeddings using `sentence-transformers/all-MiniLM-L6-v2`
- ğŸ—ƒï¸ Store in local **Chroma DB** (`CHROMA_DB1zip`)
- ğŸ§³ Zip DB folder for deployment and reuse

---

### ğŸ’¬ 4. LLM Query Interface (`/llm`)
**Goal**: Answer natural language questions using **retrieved context**

**Components**:
- ğŸ¤– **Google Gemini 2.0 Flash** via `langchain-google-genai`
- ğŸ¯ **MMR-based Retrieval** for diverse, relevant chunks
- ğŸ“„ **Source Citation** for transparency (e.g., "ITC Annual Report 2023, Page 12")

**Example Queries**:
- â€œWhat was ITCâ€™s revenue in 2024?â€
- â€œCompare profitability in 2023 vs 2024.â€
- â€œShow stock price trend around Q1 2023.â€

---

### ğŸ–¼ï¸ 5. Streamlit Chat App (`app.py`)
**Goal**: Visual front-end for financial Q&A

**Features**:
- ğŸ§  Chat with memory to maintain context
- ğŸ§¾ Answers backed by source docs
- ğŸ“Š Bullet-format summaries of financial KPIs
- ğŸ¯ Clear year-wise breakdowns


